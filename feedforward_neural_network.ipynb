{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xVjuXsr1zLu2"
   },
   "outputs": [],
   "source": [
    "#import the dataset \n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OQLWjHat0lV4"
   },
   "outputs": [],
   "source": [
    "#import the required libraries \n",
    "from matplotlib import pyplot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rP17UY7v0C7w"
   },
   "outputs": [],
   "source": [
    "#load the data into train and test \n",
    "(X_train,y_train),(X_test,y_test)=fashion_mnist.load_data()\n",
    "#pyplot.imshow(X_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z27sdlQmMH1O",
    "outputId": "24480500-1f7d-4219-a65c-76e043c3c77b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "noOfImages = X_train.shape[0]\n",
    "X_train = (1.0/255)*np.array([X_train[i].flatten() for i in range(0,noOfImages)])\n",
    "X_train = np.array([X_train[i].flatten() for i in range(0,noOfImages)])\n",
    "noOftestImages= X_test.shape[0]\n",
    "X_test =(1.0/255)*np.array([X_test[i].flatten() for i in range(0,noOftestImages)])\n",
    "X_test =np.array([X_test[i].flatten() for i in range(0,noOftestImages)])\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtQEmgi3Opy_",
    "outputId": "7255d5e6-eb7e-464b-8a1c-7485fb8c1a0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00392157 0.         0.         0.05098039 0.28627451 0.\n",
      " 0.         0.00392157 0.01568627 0.         0.         0.\n",
      " 0.         0.00392157 0.00392157 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01176471 0.\n",
      " 0.14117647 0.53333333 0.49803922 0.24313725 0.21176471 0.\n",
      " 0.         0.         0.00392157 0.01176471 0.01568627 0.\n",
      " 0.         0.01176471 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.02352941 0.         0.4        0.8\n",
      " 0.69019608 0.5254902  0.56470588 0.48235294 0.09019608 0.\n",
      " 0.         0.         0.         0.04705882 0.03921569 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.60784314 0.9254902  0.81176471 0.69803922\n",
      " 0.41960784 0.61176471 0.63137255 0.42745098 0.25098039 0.09019608\n",
      " 0.30196078 0.50980392 0.28235294 0.05882353 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.00392157 0.         0.27058824\n",
      " 0.81176471 0.8745098  0.85490196 0.84705882 0.84705882 0.63921569\n",
      " 0.49803922 0.4745098  0.47843137 0.57254902 0.55294118 0.34509804\n",
      " 0.6745098  0.25882353 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.00392157\n",
      " 0.00392157 0.00392157 0.         0.78431373 0.90980392 0.90980392\n",
      " 0.91372549 0.89803922 0.8745098  0.8745098  0.84313725 0.83529412\n",
      " 0.64313725 0.49803922 0.48235294 0.76862745 0.89803922 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.71764706 0.88235294 0.84705882 0.8745098  0.89411765\n",
      " 0.92156863 0.89019608 0.87843137 0.87058824 0.87843137 0.86666667\n",
      " 0.8745098  0.96078431 0.67843137 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.75686275\n",
      " 0.89411765 0.85490196 0.83529412 0.77647059 0.70588235 0.83137255\n",
      " 0.82352941 0.82745098 0.83529412 0.8745098  0.8627451  0.95294118\n",
      " 0.79215686 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.00392157\n",
      " 0.01176471 0.         0.04705882 0.85882353 0.8627451  0.83137255\n",
      " 0.85490196 0.75294118 0.6627451  0.89019608 0.81568627 0.85490196\n",
      " 0.87843137 0.83137255 0.88627451 0.77254902 0.81960784 0.20392157\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.02352941 0.\n",
      " 0.38823529 0.95686275 0.87058824 0.8627451  0.85490196 0.79607843\n",
      " 0.77647059 0.86666667 0.84313725 0.83529412 0.87058824 0.8627451\n",
      " 0.96078431 0.46666667 0.65490196 0.21960784 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.01568627 0.         0.         0.21568627 0.9254902\n",
      " 0.89411765 0.90196078 0.89411765 0.94117647 0.90980392 0.83529412\n",
      " 0.85490196 0.8745098  0.91764706 0.85098039 0.85098039 0.81960784\n",
      " 0.36078431 0.         0.         0.         0.00392157 0.01568627\n",
      " 0.02352941 0.02745098 0.00784314 0.         0.         0.\n",
      " 0.         0.         0.92941176 0.88627451 0.85098039 0.8745098\n",
      " 0.87058824 0.85882353 0.87058824 0.86666667 0.84705882 0.8745098\n",
      " 0.89803922 0.84313725 0.85490196 1.         0.30196078 0.\n",
      " 0.         0.01176471 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.24313725 0.56862745 0.8\n",
      " 0.89411765 0.81176471 0.83529412 0.86666667 0.85490196 0.81568627\n",
      " 0.82745098 0.85490196 0.87843137 0.8745098  0.85882353 0.84313725\n",
      " 0.87843137 0.95686275 0.62352941 0.         0.         0.\n",
      " 0.         0.         0.07058824 0.17254902 0.32156863 0.41960784\n",
      " 0.74117647 0.89411765 0.8627451  0.87058824 0.85098039 0.88627451\n",
      " 0.78431373 0.80392157 0.82745098 0.90196078 0.87843137 0.91764706\n",
      " 0.69019608 0.7372549  0.98039216 0.97254902 0.91372549 0.93333333\n",
      " 0.84313725 0.         0.         0.22352941 0.73333333 0.81568627\n",
      " 0.87843137 0.86666667 0.87843137 0.81568627 0.8        0.83921569\n",
      " 0.81568627 0.81960784 0.78431373 0.62352941 0.96078431 0.75686275\n",
      " 0.80784314 0.8745098  1.         1.         0.86666667 0.91764706\n",
      " 0.86666667 0.82745098 0.8627451  0.90980392 0.96470588 0.\n",
      " 0.01176471 0.79215686 0.89411765 0.87843137 0.86666667 0.82745098\n",
      " 0.82745098 0.83921569 0.80392157 0.80392157 0.80392157 0.8627451\n",
      " 0.94117647 0.31372549 0.58823529 1.         0.89803922 0.86666667\n",
      " 0.7372549  0.60392157 0.74901961 0.82352941 0.8        0.81960784\n",
      " 0.87058824 0.89411765 0.88235294 0.         0.38431373 0.91372549\n",
      " 0.77647059 0.82352941 0.87058824 0.89803922 0.89803922 0.91764706\n",
      " 0.97647059 0.8627451  0.76078431 0.84313725 0.85098039 0.94509804\n",
      " 0.25490196 0.28627451 0.41568627 0.45882353 0.65882353 0.85882353\n",
      " 0.86666667 0.84313725 0.85098039 0.8745098  0.8745098  0.87843137\n",
      " 0.89803922 0.11372549 0.29411765 0.8        0.83137255 0.8\n",
      " 0.75686275 0.80392157 0.82745098 0.88235294 0.84705882 0.7254902\n",
      " 0.77254902 0.80784314 0.77647059 0.83529412 0.94117647 0.76470588\n",
      " 0.89019608 0.96078431 0.9372549  0.8745098  0.85490196 0.83137255\n",
      " 0.81960784 0.87058824 0.8627451  0.86666667 0.90196078 0.2627451\n",
      " 0.18823529 0.79607843 0.71764706 0.76078431 0.83529412 0.77254902\n",
      " 0.7254902  0.74509804 0.76078431 0.75294118 0.79215686 0.83921569\n",
      " 0.85882353 0.86666667 0.8627451  0.9254902  0.88235294 0.84705882\n",
      " 0.78039216 0.80784314 0.72941176 0.70980392 0.69411765 0.6745098\n",
      " 0.70980392 0.80392157 0.80784314 0.45098039 0.         0.47843137\n",
      " 0.85882353 0.75686275 0.70196078 0.67058824 0.71764706 0.76862745\n",
      " 0.8        0.82352941 0.83529412 0.81176471 0.82745098 0.82352941\n",
      " 0.78431373 0.76862745 0.76078431 0.74901961 0.76470588 0.74901961\n",
      " 0.77647059 0.75294118 0.69019608 0.61176471 0.65490196 0.69411765\n",
      " 0.82352941 0.36078431 0.         0.         0.29019608 0.74117647\n",
      " 0.83137255 0.74901961 0.68627451 0.6745098  0.68627451 0.70980392\n",
      " 0.7254902  0.7372549  0.74117647 0.7372549  0.75686275 0.77647059\n",
      " 0.8        0.81960784 0.82352941 0.82352941 0.82745098 0.7372549\n",
      " 0.7372549  0.76078431 0.75294118 0.84705882 0.66666667 0.\n",
      " 0.00784314 0.         0.         0.         0.25882353 0.78431373\n",
      " 0.87058824 0.92941176 0.9372549  0.94901961 0.96470588 0.95294118\n",
      " 0.95686275 0.86666667 0.8627451  0.75686275 0.74901961 0.70196078\n",
      " 0.71372549 0.71372549 0.70980392 0.69019608 0.65098039 0.65882353\n",
      " 0.38823529 0.22745098 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.15686275\n",
      " 0.23921569 0.17254902 0.28235294 0.16078431 0.1372549  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GFA10HAHKCb8"
   },
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "  X=np.exp(X)\n",
    "  sum=np.sum(X,axis=0)\n",
    "  return X/sum \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4ZgtMpEAUkIA"
   },
   "outputs": [],
   "source": [
    "def sigmoidFunc(X):\n",
    "\n",
    "  return 1.0/(1.0+np.exp(-X))\n",
    "  #return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5GJHo_F55wKD"
   },
   "outputs": [],
   "source": [
    "def gDash(X):\n",
    "  return sigmoidFunc(X)*(1-sigmoidFunc(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "pIfFadrLAkmM"
   },
   "outputs": [],
   "source": [
    "def forwardPropagation(X,parameters):\n",
    "  preactivation={}\n",
    "  activation={}\n",
    "  activation['h0']=X.T\n",
    "  #print(activation['h0'].shape)\n",
    "  for k in range(1,noOfHiddenLayers+1):\n",
    "    preactivation['a'+str(k)]=np.dot(parameters['W'+str(k)],activation['h'+str(k-1)])+parameters['b'+str(k)]\n",
    "    activation['h'+str(k)]=sigmoidFunc(preactivation['a'+str(k)])\n",
    "    #print('h size '+str(k),activation['h'+str(k)].shape)\n",
    "    #print('a'+str(k),preactivation['a'+str(k)])\n",
    "  preactivation['a'+str(noOfHiddenLayers+1)]=np.dot(parameters['W'+str(noOfHiddenLayers+1)],activation['h'+str(noOfHiddenLayers)])+parameters['b'+str(noOfHiddenLayers+1)]\n",
    "  y=softmax(preactivation['a'+str(noOfHiddenLayers+1)])    \n",
    "  #print(\"a last\" ,preactivation['a'+str(noOfHiddenLayers+1)])\n",
    "  return (preactivation,activation,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "vZFsUg0xrJtv"
   },
   "outputs": [],
   "source": [
    "def backPropagation(parameters,activation,preactivation,yhat,X,y_train):\n",
    "  grads={}\n",
    "  eIndicator=np.zeros((10,X.shape[0]))\n",
    "  eIndicator[y_train,np.arange(X.shape[0])]=1\n",
    "  #print(y_train)\n",
    "  #print(eIndicator)\n",
    "  #print(eIndicator.shape)\n",
    "  grads['a'+str(noOfHiddenLayers+1)]= -(eIndicator-yhat)\n",
    "  #print(grads['a'+str(noOfHiddenLayers+1)].shape)\n",
    "  for j in range(noOfHiddenLayers+1,0,-1):\n",
    "    grads['W'+str(j)]= np.dot(grads['a'+str(j)],activation['h'+str(j-1)].T)\n",
    "    #grads['W'+str(j)]= np.dot(activation['h'+str(j-1)],grads['a'+str(j)].T).T\n",
    "    #print(grads['W'+str(j)].shape)\n",
    "    grads['b'+str(j)]= np.sum(grads['a'+str(j)],axis=1,keepdims=True)\n",
    "    ###grads['h'+str(j-1)]=np.dot(grads['W'+str(j)].T,grads['a'+str(j)]) #error\n",
    "    grads['h'+str(j-1)]=np.dot(parameters['W'+str(j)].T,grads['a'+str(j)])\n",
    "    #print('h'+str(j-1),grads['h'+str(j-1)].shape)\n",
    "    #print('a'+str(j-1),preactivation['a'+str(j-1)].shape)\n",
    "    if (j!=1):\n",
    "      grads['a'+str(j-1)]=grads['h'+str(j-1)]*gDash(preactivation['a'+str(j-1)])\n",
    "  return grads\n",
    "#backPropagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "3MXQ17Gk_Cuv"
   },
   "outputs": [],
   "source": [
    "def Loss(yhat,y_train,X):\n",
    "  eIndicator=np.zeros((10,X.shape[0]))\n",
    "  eIndicator[y_train,np.arange(X.shape[0])]=1\n",
    "  eIndicator=eIndicator*yhat\n",
    "  eIndicator=eIndicator.sum(axis=0)\n",
    "  eIndicator=np.log(eIndicator)\n",
    "  return -sum(eIndicator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WnJHWPgMiiLw",
    "outputId": "c7870bc1-8497-4ee2-da3d-243d46d689aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "iter  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arun-PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n",
      "C:\\Users\\Arun-PC\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in true_divide\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter  1\n",
      "iter  2\n",
      "iter  3\n",
      "iter  4\n",
      "iter  5\n",
      "iter  6\n",
      "iter  7\n",
      "iter  8\n",
      "iter  9\n",
      "iter  10\n",
      "iter  11\n",
      "iter  12\n",
      "iter  13\n",
      "iter  14\n",
      "iter  15\n",
      "iter  16\n",
      "iter  17\n",
      "iter  18\n",
      "iter  19\n",
      "iter  20\n",
      "iter  21\n",
      "iter  22\n",
      "iter  23\n",
      "iter  24\n",
      "iter  25\n",
      "iter  26\n",
      "iter  27\n",
      "iter  28\n",
      "iter  29\n",
      "iter  30\n",
      "iter  31\n",
      "iter  32\n",
      "iter  33\n",
      "iter  34\n",
      "iter  35\n",
      "iter  36\n",
      "iter  37\n",
      "iter  38\n",
      "iter  39\n",
      "iter  40\n",
      "iter  41\n",
      "iter  42\n",
      "iter  43\n",
      "iter  44\n",
      "iter  45\n",
      "iter  46\n",
      "iter  47\n",
      "iter  48\n",
      "iter  49\n",
      "iter  50\n",
      "iter  51\n",
      "iter  52\n",
      "iter  53\n",
      "iter  54\n",
      "iter  55\n",
      "iter  56\n",
      "iter  57\n",
      "iter  58\n",
      "iter  59\n",
      "iter  60\n",
      "iter  61\n",
      "iter  62\n",
      "iter  63\n",
      "iter  64\n",
      "iter  65\n",
      "iter  66\n",
      "iter  67\n",
      "iter  68\n",
      "iter  69\n",
      "iter  70\n",
      "iter  71\n",
      "iter  72\n",
      "iter  73\n",
      "iter  74\n",
      "iter  75\n",
      "iter  76\n",
      "iter  77\n",
      "iter  78\n",
      "iter  79\n",
      "iter  80\n",
      "iter  81\n",
      "iter  82\n",
      "iter  83\n",
      "iter  84\n",
      "iter  85\n",
      "iter  86\n",
      "iter  87\n",
      "iter  88\n",
      "iter  89\n",
      "iter  90\n",
      "iter  91\n",
      "iter  92\n",
      "iter  93\n",
      "iter  94\n",
      "iter  95\n",
      "iter  96\n",
      "iter  97\n",
      "iter  98\n",
      "iter  99\n",
      "iter  100\n",
      "iter  101\n",
      "iter  102\n",
      "iter  103\n",
      "iter  104\n",
      "iter  105\n",
      "iter  106\n",
      "iter  107\n",
      "iter  108\n",
      "iter  109\n",
      "iter  110\n",
      "iter  111\n",
      "iter  112\n",
      "iter  113\n",
      "iter  114\n",
      "iter  115\n",
      "iter  116\n",
      "iter  117\n",
      "iter  118\n",
      "iter  119\n",
      "iter  120\n",
      "iter  121\n",
      "iter  122\n",
      "iter  123\n",
      "iter  124\n",
      "iter  125\n",
      "iter  126\n",
      "iter  127\n",
      "iter  128\n",
      "iter  129\n",
      "iter  130\n",
      "iter  131\n",
      "iter  132\n",
      "iter  133\n",
      "iter  134\n",
      "iter  135\n",
      "iter  136\n",
      "iter  137\n",
      "iter  138\n",
      "iter  139\n",
      "iter  140\n",
      "iter  141\n",
      "iter  142\n",
      "iter  143\n",
      "iter  144\n",
      "iter  145\n",
      "iter  146\n",
      "iter  147\n",
      "iter  148\n",
      "iter  149\n",
      "iter  150\n",
      "iter  151\n",
      "iter  152\n",
      "iter  153\n",
      "iter  154\n",
      "iter  155\n",
      "iter  156\n",
      "iter  157\n",
      "iter  158\n",
      "iter  159\n",
      "iter  160\n",
      "iter  161\n",
      "iter  162\n",
      "iter  163\n",
      "iter  164\n",
      "iter  165\n",
      "iter  166\n",
      "iter  167\n",
      "iter  168\n",
      "iter  169\n",
      "iter  170\n",
      "iter  171\n",
      "iter  172\n",
      "iter  173\n",
      "iter  174\n",
      "iter  175\n",
      "iter  176\n",
      "iter  177\n",
      "iter  178\n",
      "iter  179\n",
      "iter  180\n",
      "iter  181\n",
      "iter  182\n",
      "iter  183\n",
      "iter  184\n",
      "iter  185\n",
      "iter  186\n",
      "iter  187\n",
      "iter  188\n",
      "iter  189\n",
      "iter  190\n",
      "iter  191\n",
      "iter  192\n",
      "iter  193\n",
      "iter  194\n",
      "iter  195\n",
      "iter  196\n",
      "iter  197\n",
      "iter  198\n",
      "iter  199\n",
      "iter  200\n",
      "iter  201\n",
      "iter  202\n",
      "iter  203\n",
      "iter  204\n",
      "iter  205\n",
      "iter  206\n",
      "iter  207\n",
      "iter  208\n",
      "iter  209\n",
      "iter  210\n",
      "iter  211\n",
      "iter  212\n",
      "iter  213\n",
      "iter  214\n",
      "iter  215\n",
      "iter  216\n",
      "iter  217\n",
      "iter  218\n",
      "iter  219\n",
      "iter  220\n",
      "iter  221\n",
      "iter  222\n",
      "iter  223\n",
      "iter  224\n",
      "iter  225\n",
      "iter  226\n",
      "iter  227\n",
      "iter  228\n",
      "iter  229\n",
      "iter  230\n",
      "iter  231\n",
      "iter  232\n",
      "iter  233\n",
      "iter  234\n",
      "iter  235\n",
      "iter  236\n",
      "iter  237\n",
      "iter  238\n",
      "iter  239\n",
      "iter  240\n",
      "iter  241\n",
      "iter  242\n",
      "iter  243\n",
      "iter  244\n",
      "iter  245\n",
      "iter  246\n",
      "iter  247\n",
      "iter  248\n",
      "iter  249\n",
      "iter  250\n",
      "iter  251\n",
      "iter  252\n",
      "iter  253\n",
      "iter  254\n",
      "iter  255\n",
      "iter  256\n",
      "iter  257\n",
      "iter  258\n",
      "iter  259\n",
      "iter  260\n",
      "iter  261\n",
      "iter  262\n",
      "iter  263\n",
      "iter  264\n",
      "iter  265\n",
      "iter  266\n",
      "iter  267\n",
      "iter  268\n",
      "iter  269\n",
      "iter  270\n",
      "iter  271\n",
      "iter  272\n",
      "iter  273\n",
      "iter  274\n",
      "iter  275\n",
      "iter  276\n",
      "iter  277\n",
      "iter  278\n",
      "iter  279\n",
      "iter  280\n",
      "iter  281\n",
      "iter  282\n",
      "iter  283\n",
      "iter  284\n",
      "iter  285\n",
      "iter  286\n",
      "iter  287\n",
      "iter  288\n",
      "iter  289\n",
      "iter  290\n",
      "iter  291\n",
      "iter  292\n",
      "iter  293\n",
      "iter  294\n",
      "iter  295\n",
      "iter  296\n",
      "iter  297\n",
      "iter  298\n",
      "iter  299\n",
      "{'W1': array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), 'b1': array([[nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan]]), 'W2': array([[nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       ...,\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan],\n",
      "       [nan, nan, nan, ..., nan, nan, nan]]), 'b2': array([[nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan]]), 'W3': array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan],\n",
      "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan]]), 'b3': array([[nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan],\n",
      "       [nan]])}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "noOfHiddenLayers=2\n",
    "l=10 #output classes\n",
    "noOfneuronsEach=[120,20]\n",
    "inputNeuronSize=X_train.shape[1]\n",
    "print(inputNeuronSize)\n",
    "parameters={}\n",
    "eta=1\n",
    "#eta=0.1\n",
    "#input W\n",
    "loss = []\n",
    "def gradDescent():\n",
    "  #batchSize=1000\n",
    "  iterations=300\n",
    "  #initialization\n",
    "  parameters['W'+str(1)] =np.random.uniform(low=-0.5,high=0.5,size=(noOfneuronsEach[0], inputNeuronSize))\n",
    "  parameters['b'+str(1)]= np.random.uniform(low=-0.5,high=0.5,size=(noOfneuronsEach[0],1))\n",
    "  #parameters['W'+str(1)] =0+1.5*np.random.randn(noOfneuronsEach[0], inputNeuronSize)\n",
    "  #parameters['b'+str(1)]= 0+1.5*np.random.randn(noOfneuronsEach[0],1)\n",
    "  for i in range(2,noOfHiddenLayers+1):\n",
    "    parameters['W'+str(i)] = np.random.uniform(low=-0.5,high=0.5,size=(noOfneuronsEach[i-1], noOfneuronsEach[i-2]))\n",
    "    parameters['b'+str(i)]= np.random.uniform(low=-0.5,high=0.5,size=(noOfneuronsEach[i-1],1))\n",
    "    #parameters['W'+str(i)] = 0+1.5*np.random.randn(noOfneuronsEach[i-1], noOfneuronsEach[i-2])\n",
    "    #parameters['b'+str(i)]= 0+1.5*np.random.randn(noOfneuronsEach[i-1],1)\n",
    "  #Output W\n",
    "  parameters['W'+str(noOfHiddenLayers+1)] = np.random.uniform(low=-0.5,high=0.5,size=(l, noOfneuronsEach[-1]))\n",
    "  parameters['b'+str(noOfHiddenLayers+1)]= np.random.uniform(low=-0.5,high=0.5,size=(l,1))\n",
    "  #parameters['W'+str(noOfHiddenLayers+1)] = 0+1.5*np.random.randn(l, noOfneuronsEach[-1])\n",
    "  #parameters['b'+str(noOfHiddenLayers+1)]= 0+1.5*np.random.randn(l,1)\n",
    "  t=0  \n",
    "  while(t < iterations):\n",
    "    print(\"iter \",t)\n",
    "    #print(parameters)\n",
    "    #mini=0\n",
    "    #while(mini<(noOfImages/batchSize)):\n",
    "      #print(\"Epoch\",mini)\n",
    "      #X_mini=X_train[(mini*batchSize):((mini+1)*batchSize-1)]\n",
    "      #y_mini=y_train[(mini*batchSize):((mini+1)*batchSize-1)]\n",
    "    # shuffle the data\n",
    "    #X_train = np.random.shuffle(X_train)\n",
    "    for x in X_train:\n",
    "        batch = np.array([x])\n",
    "        preactivation,activation,yhat=forwardPropagation(batch,parameters)\n",
    "          #print(preactivation)\n",
    "          #print(activation)\n",
    "        #print(\"y_pred\",yhat)\n",
    "        #print(\"loss\",Loss(yhat,y_train,X_train))\n",
    "        loss.append(Loss(yhat,y_train,batch))\n",
    "        gradients=backPropagation(parameters,activation,preactivation,yhat,batch,y_train)\n",
    "        #print(\"gradients\",gradients)\n",
    "        for i in range(1,noOfHiddenLayers+2):\n",
    "          parameters['W'+str(i)] -=  eta*gradients['W'+str(i)]#parameters['W'+str(i)] -=  eta*(1.0/X_train.shape[0])*gradients['W'+str(i)]\n",
    "          parameters['b'+str(i)] -= eta*gradients['b'+str(i)]#parameters['b'+str(i)] -= eta*(1.0/X_train.shape[0])*gradients['b'+str(i)]\n",
    "    #mini+=1\n",
    "    #_,_,yhat=forwardPropagation(X_train,parameters)\n",
    "    \n",
    "    #print(yhat)\n",
    "    t+=1\n",
    "gradDescent()\n",
    "pyplot.plot(loss)\n",
    "print(parameters)\n",
    "#print(gradients)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpuXKyTzYJnB",
    "outputId": "b3041b66-7bbb-4a16-c480-f8e260fa97f8"
   },
   "outputs": [],
   "source": [
    "def predict(X_test,y_test):\n",
    "  _,_,y_hat=forwardPropagation(X_test,parameters)\n",
    "  y_hat=y_hat.argmax(axis=0)\n",
    "  correctPred=np.sum(y_hat==y_test)\n",
    "  print(\"Accuracy is \", correctPred/X_test.shape[0]*100,\"%\")\n",
    "  return (y_hat,correctPred)\n",
    "print(predict(X_train,y_train))\n",
    "print(predict(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assgnment1_DL.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
